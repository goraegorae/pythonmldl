{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "764fe135-c09e-9769-5794-500867154d93",
    "_uuid": "ddb58b75d62d8bb3679841c3c060579a8a0c1eec"
   },
   "source": [
    "# Keras를 활용한 강아지, 고양이 구분 CNN 딥러닝 모델 만들기\n",
    "\n",
    "[Jeff Delaney의 노트북](https://www.kaggle.com/jeffd23/catdognet-keras-convnet-starter)을 기반으로 최신 Keras에 맞게 수정 및 성능 향상을 위한 작업 추가\n",
    "\n",
    "[kaggle Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)에 출전할 만한 데이터를 만들어 봅시다! 이미지를 처리하기 위한 CNN (Convolution Neural Network)의 특성을 이해하고 70% 이상의 정확도를 보이는 모형을 만들기 위해 필요한 조건을 알아봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras의 백엔드 프레임워크로 Tensorflow를 사용합니다\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실습을 진행하기 위해 선생님 그래픽카드 중 어떤 카드를 쓸지\n",
    "# 해당 카드의 GPU 메모리를 몇 % 사용할지 설정하는 부분입니다\n",
    "# 실습을 위한 것이므로 일반적인 환경에서는 필요 없습니다 (몰라도 됨)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# 이 셀을 실행하고 *이 사라진 것을 확인 후 다음으로 진행하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d458c15-e131-f3c4-f756-843d6454bb37",
    "_uuid": "409ccdc7839c1ec7ffce47aa51997ccadd45eb72",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04681981-55ac-7820-a0ae-38f98c851c39",
    "_uuid": "6963ee5c15fe2a0e40449ba2cb20c220c9619ea3"
   },
   "source": [
    "## 데이터 준비\n",
    "\n",
    "train 데이터와 test 데이터를 각각의 폴더에서 읽고, 가로 128 세로 128, RGB 3채널의 이미지로 변환하여 입력 데이터로 만드는 작업을 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "663d335e-1b84-a8cb-19ee-8f04839cf4e5",
    "_uuid": "d3c854d3e0605b9dd6b5b00b15db212e7e5cdee2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train/'\n",
    "TEST_DIR = 'data/test/'\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "train_images = train_dogs[:] + train_cats[:]\n",
    "random.shuffle(train_images)\n",
    "\n",
    "test_images =  test_images[:]\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) # cv2.IMREAD_COLOR / cv2.IMREAD_GRAYSCALE\n",
    "    img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    b, g, r = cv2.split(img)   # img파일을 b,g,r로 분리\n",
    "    img2 = cv2.merge([r / 255,g / 255,b / 255]) # b, r을 바꿔서 Merge\n",
    "    return img2\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.float32)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i % 500 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data\n",
    "\n",
    "train = prep_data(train_images)\n",
    "test = prep_data(test_images)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed0fc95a-53bc-3517-245d-cf1f5122bc2d",
    "_uuid": "18f97010b742fb63a8d0f864039dc29dff615273"
   },
   "source": [
    "### 라벨 생성\n",
    "\n",
    "MNIST와 달리 여기서는 강아지와 고양이라는 2개의 클래스가 있습니다. 고양이를 0, 강아지를 1로 보고 각각의 이미지에 dog란 글자가 들은 것은 강아지로, 아닌 것은 고양이로 라벨을 붙입시다. 이후 해당 라벨을 딥러닝에 적합한 one-hot vector로 만듭니다.\n",
    "\n",
    "고양이 = 0 -> [1, 0]\n",
    "강아지 = 1 -> [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0f2fbf6-8d78-7d42-6579-5486a36c1e60",
    "_uuid": "a90fcb7a25078a84de0b497f014a8ca81341b3f5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'dog' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "sns.countplot(labels)\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    "#sns.plt.title('Cats and Dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Data 데이터 증강\n",
    "\n",
    "25000개의 데이터는 많긴 하지만 복잡하고 깊은 CNN 모델을 훈련시키기에는 조금 부족하기도 합니다. 5000개를 validation 데이터로 할당하고, 나머지 20000개의 훈련용 데이터에 대해 좌우 반전된 이미지를 추가로 생성하여 훈련에 사용하도록 합시다. 이렇게 좌우반전 혹은 이동, 자르기, 확대축소, 회전 등을 가해 원본 이미지로부터 새로운 훈련용 이미지를 만드는 것을 data augmentation 이라고 하며 특히 이미지 처리용 딥러닝에서 많이 쓰이는 기법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train[22500:].copy()\n",
    "val_labels = labels[22500:].copy()\n",
    "train = train[:22500].copy()\n",
    "labels = labels[:22500].copy()\n",
    "\n",
    "print(len(train))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img):\n",
    "    rimg=img.copy()\n",
    "    rimg=cv2.flip(img,1)\n",
    "    return rimg.T\n",
    "\n",
    "aug_train = np.ndarray((train.shape[0], CHANNELS, ROWS, COLS), dtype=np.float32)\n",
    "aug_labels = labels.copy()\n",
    "\n",
    "idx = 0\n",
    "for i in train:\n",
    "    aug_train[idx] = horizontal_flip(i.T)\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(aug_train[0].T)\n",
    "plt.show()\n",
    "plt.imshow(train[0].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bb0bd2a-0512-aa72-c628-5b6ac946d97c",
    "_uuid": "4f6752a1c8e6b8199a61906418ba0720c239c268"
   },
   "source": [
    "### 데이터 확인\n",
    "\n",
    "우리가 다룰 강아지와 고양이 사진을 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b7c79ae-6543-2ed8-e3f5-af4f5beb9cf7",
    "_uuid": "c0a85fd10a365862480ea042841b24b8bcc6c4bc"
   },
   "outputs": [],
   "source": [
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(train_cats[idx])\n",
    "    dog = read_image(train_dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "start = 1000\n",
    "for idx in range(start,start + 5):\n",
    "    show_cats_and_dogs(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "51e403b6-bcfc-b4fa-3770-9850cc86bae3",
    "_uuid": "78c9251450de032f3e843dad35851df15f47254b"
   },
   "source": [
    "## 모델 만들기\n",
    "\n",
    "다양한 모델에 대해 모형을 return 하는 함수를 만들어보며 테스트해봅시다.\n",
    "\n",
    "커다란 딥러닝 모형은 설정할 부분이 매우 많고, 경우에 따라 작은 설정 값 하나의 변화가 극적인 성능변화를 일으키기도 합니다. 또한 각각의 값들이 서로 상호작용하기도 하므로, 매우 많은 시행착오가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.0001)\n",
    "\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c477612-41d3-3112-5176-3c4ad9633080",
    "_uuid": "4403e9826eb892a018040213af643a0602dffa03",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def catdog():    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    model_name = 'catdog'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def catdog2():    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    model_name = 'catdog2'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tri():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(8, (9, 9), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(16, (7, 7), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(32, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    model_name = 'tri'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def big():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    model_name = 'big'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b7fbf156-2268-62ce-5fed-52a09af5e6f7",
    "_uuid": "bfff160827b7fc09513c3c15c355c5aa013207e1"
   },
   "source": [
    "### Train and Predict\n",
    "\n",
    "I'm using Keras's early stopping callback to end training when the validation loss stops improving, otherwise the model will overfit. I will also be tracking the loss history on each epoch to visualize the overfitting trend. \n",
    "\n",
    "Note: A slice of 1000 images was used to fit the model for CPU efficency. The model's perfrmance improves significantly when used on the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catdog()\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca613169-4b41-e9d5-27c7-6629f8e035c8",
    "_uuid": "425b112eea459e10997520f44a9638810958ce7d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 3\n",
    "batch_size = 128\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "def run_catdog():\n",
    "    \n",
    "    history = LossHistory()\n",
    "    train_whole = np.concatenate((train, aug_train), axis = 0)\n",
    "    labels_whole = np.concatenate((labels, aug_labels), axis = 0)\n",
    "    model.fit(train_whole, labels_whole, batch_size=batch_size, epochs=nb_epoch,\n",
    "              validation_data=(val_data, val_labels), verbose=1, shuffle=True, callbacks=[history])\n",
    "    predictions = model.predict(test, verbose=0)\n",
    "    return predictions, history\n",
    "\n",
    "predictions, history = run_catdog()\n",
    "\n",
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d9382e7d-31db-0d75-6876-aaccb126e4f6",
    "_uuid": "4c2066c6175a281c7f4198fe00f29450a2926dd7"
   },
   "source": [
    "## How'd We Do?\n",
    "\n",
    "I'm pretty sure I can distinguish a cat from a dog 100% of the time, but how confident is the model?...\n",
    "\n",
    "Tip: Run on the full dataset with a GPU for a LB logloss of ~0.4 and accuracy at approx 90%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c665d01b-a5a7-2f7e-e5d4-09e108920e40",
    "_uuid": "bc291ab57e77fd2ee0093d82bfc59e894cbdcf4b",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplots_adjust(left=0, right=2, bottom=0, top=2.5)\n",
    "for i in range(0,16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    #idx = random.randrange(0, predictions.shape[0])\n",
    "    idx = i\n",
    "    if predictions[idx][0] >= 0.5: \n",
    "        plt.title('{} Cat {:.2%}'.format(idx+1, predictions[idx][0]))\n",
    "    else: \n",
    "        plt.title('{} Dog {:.2%}'.format(idx+1, predictions[idx][1]))\n",
    "    plt.imshow(test[idx].T)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
